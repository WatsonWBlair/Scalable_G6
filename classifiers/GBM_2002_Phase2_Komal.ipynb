{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENZRrmTgX8rr"
      },
      "source": [
        "\n",
        "\n",
        "**Step 1: Load the dataset and drop TailNum**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHM18avfVE8H"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYEeUSBUWKQO"
      },
      "outputs": [],
      "source": [
        "# Load the csv file from drive\n",
        "k_df=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/FlightCSV/Copy of FlightData.csv')\n",
        "k_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdGqwhllXD-I"
      },
      "outputs": [],
      "source": [
        "k_df.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyLg5dr-XUD_"
      },
      "outputs": [],
      "source": [
        "# Drop 'TailNum' column\n",
        "k_df = k_df.drop(columns=['TailNum'], errors='ignore')\n",
        "k_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JD3nbsDgYDUx"
      },
      "source": [
        "**Step:2 Define the target â€” flight delay **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6hzvKnIX3bP"
      },
      "outputs": [],
      "source": [
        "# Use the condition for Delayed column\n",
        "# Convert 'ArrDelay' column to numeric, coerce errors to NaN\n",
        "k_df['ArrDelay'] = pd.to_numeric(k_df['ArrDelay'], errors='coerce')\n",
        "# Apply the lambda function to create the 'Delayed' column\n",
        "k_df['Delayed'] = k_df['ArrDelay'].apply(lambda x: 1 if x > 15 else 0)\n",
        "\n",
        "k_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dS3LSmhaHES"
      },
      "source": [
        "**Step:3)Preprocess the Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOgkRghuaBSN"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "#Drop target related column to avoid Leakege\n",
        "X = k_df.drop(columns=['ArrDelay','Delayed'])\n",
        "y = k_df['Delayed']\n",
        "\n",
        "#Verify ArrDelay and Delayed columns were created\n",
        "print(k_df.columns)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvqduJm5dY8x"
      },
      "outputs": [],
      "source": [
        "# Drop target related column to avoid Leakege\n",
        "X = k_df.drop(columns=['ArrDelay','Delayed'])\n",
        "y = k_df['Delayed']\n",
        "\n",
        "#Identify object (categorical) columns\n",
        "cat_cols = X.select_dtypes(include=['object']).columns\n",
        "print(cat_cols)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZ_TDUE3fZrX"
      },
      "outputs": [],
      "source": [
        "#Identify Numerical Columns\n",
        "num_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "print(num_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubGBqTTyfb4l"
      },
      "outputs": [],
      "source": [
        "# Drop high-cardinality object columns (optional: choose based on cardinality)\n",
        "high_card_cols = [col for col in cat_cols if X[col].nunique() > 100]\n",
        "X.drop(columns=high_card_cols, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opwgndLXfk2U"
      },
      "outputs": [],
      "source": [
        "# Label encode remaining categorical columns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoders = {}\n",
        "for col in X.select_dtypes(include='object').columns:\n",
        "    le = LabelEncoder()\n",
        "    X[col] = le.fit_transform(X[col].astype(str))\n",
        "    label_encoders[col] = le"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jm6cWtacfpJU"
      },
      "outputs": [],
      "source": [
        "# Fill missing values efficiently (numeric only now)\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrHiRJDGftNE"
      },
      "outputs": [],
      "source": [
        "# Train/test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-aC9AlXgD57"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "gbm = GradientBoostingClassifier(random_state=42)\n",
        "gbm.fit(X_train, y_train)\n",
        "y_pred = gbm.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYsyqlTggtNl"
      },
      "outputs": [],
      "source": [
        "#Let's plot the distribution of the Delayed column to understand how many flights were delayed vs. on time.\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(x='Delayed', data=k_df, palette='Set2')\n",
        "plt.title('Flight Delay Distribution')\n",
        "plt.xlabel('Delayed (0 = No, 1 = Yes)')\n",
        "plt.ylabel('Number of Flights')\n",
        "plt.xticks([0, 1], ['On Time', 'Delayed'])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kC0iALRtHAN"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, accuracy_score, f1_score, classification_report\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = gbm.predict(X_test)\n",
        "\n",
        "# Binary classification metrics\n",
        "precision = precision_score(y_test, y_pred)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f\"Accuracy Score:  {accuracy:.4f}\")\n",
        "print(f\"Precision Score: {precision:.4f}\")\n",
        "print(f\"F1 Score:        {f1:.4f}\")\n",
        "\n",
        "# Optional: detailed classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHj6tRWQgYw8"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Get feature importances\n",
        "importances = gbm.feature_importances_\n",
        "feature_names = X.columns\n",
        "feature_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': importances\n",
        "})\n",
        "\n",
        "# Sort by importance\n",
        "feature_df = feature_df.sort_values(by='Importance', ascending=False).head(15)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Importance', y='Feature', data=feature_df, palette='viridis')\n",
        "plt.title('Top 15 Important Features in Predicting Flight Delays')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZhfmYfTjl7W"
      },
      "outputs": [],
      "source": [
        "#Code to View Arrival and Departure Delays\n",
        "# Display the first few rows of arrival and departure delays\n",
        "k_df[['ArrDelay', 'DepDelay']].head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uwAxETTlrbS"
      },
      "outputs": [],
      "source": [
        "#If you want to explore their statistics (like mean, std, min, max), you can also do:\n",
        "\n",
        "k_df[['ArrDelay', 'DepDelay']].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cFrD_nKl246"
      },
      "outputs": [],
      "source": [
        "#Or, if you want to print all rows of just those two columns:\n",
        "# Show all rows for ArrDelay and DepDelay (use with caution for large datasets)\n",
        "print(k_df[['ArrDelay', 'DepDelay','Delayed']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yuy9G7i2m3L3"
      },
      "outputs": [],
      "source": [
        "#delays across specific years (1997,2002, 2005, 2006, 2007)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Filter for the specific years\n",
        "years_of_interest = [1997, 2002, 2005, 2006, 2007]\n",
        "df_years = k_df[k_df['Year'].isin(years_of_interest)]\n",
        "\n",
        "# Group by year and delayed flag\n",
        "delay_by_year = df_years.groupby(['Year', 'Delayed']).size().reset_index(name='Count')\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(data=delay_by_year, x='Year', y='Count', hue='Delayed', palette='Set1')\n",
        "plt.title('Flight Delays (Delayed vs On-Time) for Selected Years')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Number of Flights')\n",
        "plt.legend(title='Delayed (0 = On-Time, 1 = Delayed)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8F0dWy5wAQZ"
      },
      "outputs": [],
      "source": [
        "missing_values = k_df.isnull().sum()\n",
        "print(\"Missing values per column:\\n\", missing_values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxElfb12wEn_"
      },
      "outputs": [],
      "source": [
        "print(\"Data types of each column:\\n\", k_df.dtypes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QEP31p2wfAG"
      },
      "outputs": [],
      "source": [
        "duplicates = k_df.duplicated()\n",
        "print(f\"Number of duplicate rows: {duplicates.sum()}\")\n",
        "k_df = k_df.drop_duplicates()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hl9jyXdqwpti"
      },
      "outputs": [],
      "source": [
        "print(\"Arrival Delay statistics:\\n\", k_df['ArrDelay'].describe())\n",
        "print(\"Departure Delay statistics:\\n\", k_df['DepDelay'].describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5du2Bv5dyGRP"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = gbm.predict(X_test)\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Display confusion matrix\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['On Time (0)', 'Delayed (1)'])\n",
        "disp.plot(cmap='Blues')\n",
        "plt.title(\"Confusion Matrix - GBM Model\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yu3ECAoWymB0"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get predicted probabilities for the positive class (Delayed = 1)\n",
        "y_probs = gbm.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Compute False Positive Rate, True Positive Rate, and thresholds\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
        "\n",
        "# Compute AUC (Area Under Curve)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot ROC Curve\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'GBM ROC curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate (FPR)')\n",
        "plt.ylabel('True Positive Rate (TPR)')\n",
        "plt.title('ROC Curve - GBM Model')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAQH34ajzERs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Get prediction probabilities for class 1 (Delayed)\n",
        "y_probs = gbm.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Create threshold values between 0 and 1\n",
        "thresholds = np.linspace(0, 1, 100)\n",
        "false_positives = []\n",
        "false_negatives = []\n",
        "\n",
        "# Loop through each threshold\n",
        "for thresh in thresholds:\n",
        "    y_pred_thresh = (y_probs >= thresh).astype(int)\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_thresh).ravel()\n",
        "    false_positives.append(fp)\n",
        "    false_negatives.append(fn)\n",
        "\n",
        "# Plot FP and FN\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(thresholds, false_positives, label='False Positives', color='red')\n",
        "plt.plot(thresholds, false_negatives, label='False Negatives', color='blue')\n",
        "plt.title('False Positives and False Negatives vs Classification Threshold')\n",
        "plt.xlabel('Threshold')\n",
        "plt.ylabel('Count')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "va2AzYY5zbZk"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "# Prepare arrays\n",
        "precision_list = []\n",
        "recall_list = []\n",
        "thresholds = np.linspace(0, 1, 100)\n",
        "\n",
        "# Loop through thresholds and compute precision and recall\n",
        "for thresh in thresholds:\n",
        "    y_pred_thresh = (y_probs >= thresh).astype(int)\n",
        "    precision = precision_score(y_test, y_pred_thresh, zero_division=0)\n",
        "    recall = recall_score(y_test, y_pred_thresh)\n",
        "    precision_list.append(precision)\n",
        "    recall_list.append(recall)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(thresholds, precision_list, label='Precision', color='green')\n",
        "plt.plot(thresholds, recall_list, label='Recall', color='purple')\n",
        "plt.title('Precision and Recall vs Classification Threshold')\n",
        "plt.xlabel('Threshold')\n",
        "plt.ylabel('Score')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kkZRy486zeK"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define model names\n",
        "models = [\"Random Forest\", \"SGD Classifier\", \"Logistic Regression\", \"XGBoost\", \"Gradient Boosting\"]\n",
        "\n",
        "# Define metrics\n",
        "accuracy = [0.70, 0.71, 0.72, 0.91, 0.81]\n",
        "precision = [0.70, 0.72, 0.72, 0.91, 0.82]\n",
        "recall = [0.70, 0.71, 0.72, 0.91, 0.50]\n",
        "f1_score = [0.70, 0.71, 0.72, 0.91, 0.72]\n",
        "\n",
        "# Set position of bar on X axis\n",
        "x = np.arange(len(models))\n",
        "width = 0.2  # Width of bars\n",
        "\n",
        "# Plotting the grouped bar chart\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(x - 1.5*width, accuracy, width, label='Accuracy')\n",
        "plt.bar(x - 0.5*width, precision, width, label='Precision')\n",
        "plt.bar(x + 0.5*width, recall, width, label='Recall')\n",
        "plt.bar(x + 1.5*width, f1_score, width, label='F1 Score')\n",
        "\n",
        "# Labels and Title\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Scores')\n",
        "plt.title('Model Comparison Based on Classification Metrics')\n",
        "plt.xticks(x, models, rotation=15)\n",
        "plt.ylim(0, 1.05)\n",
        "plt.legend()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Iq24KPO8Byz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Step 4: Extract useful time-based features if 'CRSDepTime' exists\n",
        "if 'CRSDepTime' in k_df.columns:\n",
        "    k_df['CRSDepTime'] = pd.to_numeric(k_df['CRSDepTime'], errors='coerce')\n",
        "    k_df['DepHour'] = k_df['CRSDepTime'] // 100\n",
        "    k_df['DepMinute'] = k_df['CRSDepTime'] % 100\n",
        "\n",
        "# Step 5: Encode categorical variables (e.g., Origin, Dest, Carrier)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "for col in k_df.select_dtypes(include='object').columns:\n",
        "    # Use k_df instead of df\n",
        "    k_df[col] = LabelEncoder().fit_transform(k_df[col].astype(str))\n",
        "\n",
        "# Step 6: Handle missing values\n",
        "k_df.fillna(k_df.mean(numeric_only=True), inplace=True)\n",
        "\n",
        "# Step 7: Normalize/scale features if needed (optional, for model input)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "features = k_df.drop(columns=['Delayed'])  # exclude label\n",
        "scaler = StandardScaler()\n",
        "df_scaled = pd.DataFrame(scaler.fit_transform(features), columns=features.columns)\n",
        "df_scaled['Delayed'] =k_df['Delayed']  # re-add the label\n",
        "\n",
        "# Step 8: Show 10 samples\n",
        "sample_10 = df_scaled.sample(10, random_state=42)\n",
        "print(sample_10)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
